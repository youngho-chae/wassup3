{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5481ba9a-6b04-4be2-b9e4-cbc61e7c0df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "검색어: 제주도\n",
      "스크래핑 할 건수는 몇건입니까?:  100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크래핑 프로그램 실행\n",
      "====== 1 페이지 스크래핑 시작 ======\n",
      "[콘텐츠 1]\n",
      "해변산책부터 레이싱까지, 제주 반려동물 동반여행 추천 코스\n",
      "[콘텐츠 2]\n"
     ]
    },
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: stale element not found\n  (Session info: chrome=124.0.6367.158); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7C5601522+60802]\n\t(No symbol) [0x00007FF7C557AC22]\n\t(No symbol) [0x00007FF7C5437CE4]\n\t(No symbol) [0x00007FF7C544A051]\n\t(No symbol) [0x00007FF7C544AA7A]\n\t(No symbol) [0x00007FF7C543E95B]\n\t(No symbol) [0x00007FF7C543C781]\n\t(No symbol) [0x00007FF7C54401DB]\n\t(No symbol) [0x00007FF7C5440280]\n\t(No symbol) [0x00007FF7C5487A4C]\n\t(No symbol) [0x00007FF7C5487B32]\n\t(No symbol) [0x00007FF7C547DDFB]\n\t(No symbol) [0x00007FF7C54AAB7A]\n\t(No symbol) [0x00007FF7C547A7C6]\n\t(No symbol) [0x00007FF7C54AAD90]\n\t(No symbol) [0x00007FF7C54CA224]\n\t(No symbol) [0x00007FF7C54AA923]\n\t(No symbol) [0x00007FF7C5478FEC]\n\t(No symbol) [0x00007FF7C5479C21]\n\tGetHandleVerifier [0x00007FF7C59041BD+3217949]\n\tGetHandleVerifier [0x00007FF7C5946157+3488183]\n\tGetHandleVerifier [0x00007FF7C593F0DF+3459391]\n\tGetHandleVerifier [0x00007FF7C56BB8E6+823622]\n\t(No symbol) [0x00007FF7C5585FBF]\n\t(No symbol) [0x00007FF7C5580EE4]\n\t(No symbol) [0x00007FF7C5581072]\n\t(No symbol) [0x00007FF7C55718C4]\n\tBaseThreadInitThunk [0x00007FFB6D8D257D+29]\n\tRtlUserThreadStart [0x00007FFB6F94AF28+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_no \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, page_cnt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):    \n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m====== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 페이지 스크래핑 시작 ======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m     page_work()\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m====== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 페이지 스크래핑 작업중 ======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     93\u001b[0m     file_export()\n",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m, in \u001b[0;36mpage_work\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m contents_no \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m cnt :    \n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[콘텐츠 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontents_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m---> 44\u001b[0m     item\u001b[38;5;241m.\u001b[39msend_keys(Keys\u001b[38;5;241m.\u001b[39mENTER) \u001b[38;5;66;03m# .click()은 에러 잘남\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# 이미지 추출을 위해 미리 스크롤\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    228\u001b[0m             remote_files\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload(file))\n\u001b[0;32m    229\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remote_files)\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(\n\u001b[0;32m    232\u001b[0m     Command\u001b[38;5;241m.\u001b[39mSEND_KEYS_TO_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(keys_to_typing(value)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: keys_to_typing(value)}\n\u001b[0;32m    233\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: stale element not found\n  (Session info: chrome=124.0.6367.158); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7C5601522+60802]\n\t(No symbol) [0x00007FF7C557AC22]\n\t(No symbol) [0x00007FF7C5437CE4]\n\t(No symbol) [0x00007FF7C544A051]\n\t(No symbol) [0x00007FF7C544AA7A]\n\t(No symbol) [0x00007FF7C543E95B]\n\t(No symbol) [0x00007FF7C543C781]\n\t(No symbol) [0x00007FF7C54401DB]\n\t(No symbol) [0x00007FF7C5440280]\n\t(No symbol) [0x00007FF7C5487A4C]\n\t(No symbol) [0x00007FF7C5487B32]\n\t(No symbol) [0x00007FF7C547DDFB]\n\t(No symbol) [0x00007FF7C54AAB7A]\n\t(No symbol) [0x00007FF7C547A7C6]\n\t(No symbol) [0x00007FF7C54AAD90]\n\t(No symbol) [0x00007FF7C54CA224]\n\t(No symbol) [0x00007FF7C54AA923]\n\t(No symbol) [0x00007FF7C5478FEC]\n\t(No symbol) [0x00007FF7C5479C21]\n\tGetHandleVerifier [0x00007FF7C59041BD+3217949]\n\tGetHandleVerifier [0x00007FF7C5946157+3488183]\n\tGetHandleVerifier [0x00007FF7C593F0DF+3459391]\n\tGetHandleVerifier [0x00007FF7C56BB8E6+823622]\n\t(No symbol) [0x00007FF7C5585FBF]\n\t(No symbol) [0x00007FF7C5580EE4]\n\t(No symbol) [0x00007FF7C5581072]\n\t(No symbol) [0x00007FF7C55718C4]\n\tBaseThreadInitThunk [0x00007FFB6D8D257D+29]\n\tRtlUserThreadStart [0x00007FFB6F94AF28+40]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import math, time, os, pandas as pd, urllib.request\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--window-size=974,1047')\n",
    "options.add_argument('--window-position=-7,0')\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "search = input('검색어:')\n",
    "cnt = int(input('스크래핑 할 건수는 몇건입니까?: '))\n",
    "page_cnt = math.ceil(cnt / 10)  # 크롤링 할 전체 페이지 수 \n",
    "\n",
    "now = time.localtime()\n",
    "date_format = '%04d%02d%02d'%(now.tm_year, now.tm_mon, now.tm_mday)\n",
    "f_dir = f'{os.getcwd()}\\\\{search}여행기사_{cnt}건_{date_format}'\n",
    "os.makedirs(f_dir)\n",
    "\n",
    "URL = 'https://korean.visitkorea.or.kr/search/search_list.do?keyword='+search\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(URL)\n",
    "time.sleep(2)\n",
    "# 여행기사 더보기 클릭\n",
    "driver.find_element(By.CSS_SELECTOR, \"#s_recommend > .more_view > a\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "title_list = []\n",
    "contents_list = []\n",
    "img_url_list = []\n",
    "\n",
    "def page_work():\n",
    "    result = driver.find_elements(By.CSS_SELECTOR,'#search_result .tit>a')\n",
    "    global contents_no, cnt\n",
    "    global title_list, contents_list, img_url_list\n",
    "\n",
    "    for item in result:\n",
    "        contents_no += 1\n",
    "\n",
    "        if contents_no <= cnt :    \n",
    "            print(f'[콘텐츠 {contents_no}]')  \n",
    "            item.send_keys(Keys.ENTER) # .click()은 에러 잘남\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            # 이미지 추출을 위해 미리 스크롤\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "            html = driver.page_source\n",
    "            html_dom = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            title = html_dom.find(id='topTitle')\n",
    "            title_list.append(title.text)\n",
    "            print(title.text)\n",
    "\n",
    "            img_tag_list = html_dom.select('.img_typeBox img')\n",
    "            img_url_list = [item['src'] for item in img_tag_list]\n",
    "\n",
    "            contents = driver.find_elements(By.CLASS_NAME, 'txt_p')\n",
    "            contents_merge = ' '.join([item.text for item in contents])        \n",
    "            contents_list.append(contents_merge)           \n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(2)     \n",
    "\n",
    "\n",
    "def file_export():\n",
    "\n",
    "    DF = pd.DataFrame({\"제목\":title_list, \"내용\":contents_list})\n",
    "    filename = f'{search}여행기사_{cnt}건_{date_format}.xlsx'\n",
    "    DF.to_excel(f_dir+'\\\\'+filename)\n",
    "    print(f'====== {page_no} 페이지 {filename} 파일 저장 완료 ======')\n",
    "\n",
    "\n",
    "    no = 0\n",
    "    for src in img_url_list:\n",
    "        # 다운로드  (주소, 파일이름)\n",
    "        urllib.request.urlretrieve(src, f'{f_dir}\\\\{page_no}_{no}.jpg')\n",
    "        no += 1\n",
    "    print(f'====== {page_no} 페이지 {f_dir} 디렉토리 이미지 저장 완료 ======')\n",
    "\n",
    "\n",
    "contents_no = 0\n",
    "today = time.localtime()\n",
    "print('스크래핑 프로그램 실행')\n",
    "\n",
    "for page_no in range(1, page_cnt+1):    \n",
    "    print(f'====== {page_no} 페이지 스크래핑 시작 ======')\n",
    "    page_work()\n",
    "    print(f'====== {page_no} 페이지 스크래핑 작업중 ======')\n",
    "    file_export()\n",
    "    print(f'====== {page_no} 페이지 스크래핑 완료 ======')\n",
    "    if page_no < page_cnt:\n",
    "        driver.find_element(By.XPATH, f'/html/body/div[3]/div/div[1]/div[14]/a[{page_no+1}]').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "print('스크래핑 프로그램 종료')\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dee46b53-a09a-4ece-a001-757a4a2e71ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "검색어: 제주도\n",
      "스크래핑 할 건수는 몇건입니까?:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크래핑 프로그램 실행\n",
      "====== 1 페이지 스크래핑 시작 ======\n",
      "[콘텐츠 1]\n",
      "[콘텐츠 1] 해변산책부터 레이싱까지, 제주 반려동물 동반여행 추천 코스\n",
      "[콘텐츠 2]\n",
      "[콘텐츠 2] 해변산책부터 레이싱까지, 제주 반려동물 동반여행 추천 코스\n",
      "[콘텐츠 3]\n",
      "[콘텐츠 3] 해변산책부터 레이싱까지, 제주 반려동물 동반여행 추천 코스\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 104\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_no \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, page_cnt \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m====== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 페이지 스크래핑 시작 ======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m     page_work()\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m====== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 페이지 스크래핑 작업중 ======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m     file_export()\n",
      "Cell \u001b[1;32mIn[14], line 81\u001b[0m, in \u001b[0;36mpage_work\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m contents_list\u001b[38;5;241m.\u001b[39mappend(contents_merge)\n\u001b[0;32m     80\u001b[0m driver\u001b[38;5;241m.\u001b[39mback()\n\u001b[1;32m---> 81\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import math, time, os, pandas as pd, urllib.request\n",
    "\n",
    "# 크롬 브라우저 옵션 설정\n",
    "options = Options()\n",
    "options.add_argument('--window-size=974,1047')\n",
    "options.add_argument('--window-position=-7,0')\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "# 검색어와 스크래핑할 건수 입력받기\n",
    "search = input('검색어:')\n",
    "cnt = int(input('스크래핑 할 건수는 몇건입니까?: '))\n",
    "page_cnt = math.ceil(cnt / 10)  # 크롤링 할 전체 페이지 수 계산\n",
    "\n",
    "# 현재 날짜로 디렉토리 생성\n",
    "now = time.localtime()\n",
    "date_format = '%04d%02d%02d' % (now.tm_year, now.tm_mon, now.tm_mday)\n",
    "f_dir = f'{os.getcwd()}\\\\{search}여행기사_{cnt}건_{date_format}'\n",
    "os.makedirs(f_dir)\n",
    "\n",
    "# 검색어로 URL 생성 및 브라우저 열기\n",
    "URL = 'https://korean.visitkorea.or.kr/search/search_list.do?keyword=' + search\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(URL)\n",
    "time.sleep(2)\n",
    "\n",
    "# 여행기사 더보기 클릭\n",
    "driver.find_element(By.CSS_SELECTOR, \"#s_recommend > .more_view > a\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "# 데이터 저장을 위한 리스트 초기화\n",
    "title_list = []\n",
    "contents_list = []\n",
    "img_url_list = []\n",
    "\n",
    "# 개별 콘텐츠 링크 추출 후 방문 및 데이터 스크래핑\n",
    "def page_work():\n",
    "    global contents_no, cnt\n",
    "    global title_list, contents_list, img_url_list\n",
    "\n",
    "    result = driver.find_elements(By.CSS_SELECTOR, '#search_result .tit>a')\n",
    "\n",
    "    for item in result:\n",
    "        contents_no += 1\n",
    "\n",
    "        if contents_no <= cnt:\n",
    "            print(f'[콘텐츠 {contents_no}]')\n",
    "            try:\n",
    "                item.send_keys(Keys.ENTER)  # .click()은 에러 잘남\n",
    "            except StaleElementReferenceException:\n",
    "                item = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '#search_result .tit>a')))\n",
    "                item.send_keys(Keys.ENTER)\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            # 이미지 추출을 위해 미리 스크롤\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "            html = driver.page_source\n",
    "            html_dom = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            title = html_dom.find(id='topTitle')\n",
    "            title_list.append(title.text)\n",
    "            print(f'[콘텐츠 {contents_no}] {title.text}')\n",
    "\n",
    "            img_tag_list = html_dom.select('.img_typeBox img')\n",
    "            img_url_list += [item['src'] for item in img_tag_list]\n",
    "\n",
    "            contents = driver.find_elements(By.CLASS_NAME, 'txt_p')\n",
    "            contents_merge = ' '.join([item.text for item in contents])\n",
    "            contents_list.append(contents_merge)\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(5)\n",
    "\n",
    "# 스크래핑한 데이터를 파일로 저장\n",
    "def file_export():\n",
    "    DF = pd.DataFrame({\"제목\": title_list, \"내용\": contents_list})\n",
    "    filename = f'{search}여행기사_{cnt}건_{date_format}.xlsx'\n",
    "    DF.to_excel(f_dir + '\\\\' + filename)\n",
    "    print(f'====== 페이지 {filename} 파일 저장 완료 ======')\n",
    "\n",
    "    no = 0\n",
    "    for src in img_url_list:\n",
    "        # 이미지 다운로드\n",
    "        urllib.request.urlretrieve(src, f'{f_dir}\\\\img_{no}.jpg')\n",
    "        no += 1\n",
    "    print(f'====== 페이지 {f_dir} 디렉토리 이미지 저장 완료 ======')\n",
    "\n",
    "# 스크래핑 실행\n",
    "contents_no = 0\n",
    "today = time.localtime()\n",
    "print('스크래핑 프로그램 실행')\n",
    "\n",
    "for page_no in range(1, page_cnt + 1):\n",
    "    print(f'====== {page_no} 페이지 스크래핑 시작 ======')\n",
    "    page_work()\n",
    "    print(f'====== {page_no} 페이지 스크래핑 작업중 ======')\n",
    "    file_export()\n",
    "    print(f'====== {page_no} 페이지 스크래핑 완료 ======')\n",
    "    if page_no < page_cnt:\n",
    "        next_page_xpath = f'/html/body/div[3]/div/div[1]/div[14]/a[{page_no + 1}]'\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, next_page_xpath).click()\n",
    "        except StaleElementReferenceException:\n",
    "            next_page_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, next_page_xpath)))\n",
    "            next_page_button.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "print('스크래핑 프로그램 종료')\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e0a4a-c6a3-4b96-a9b6-e0d7b3b6bb65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
